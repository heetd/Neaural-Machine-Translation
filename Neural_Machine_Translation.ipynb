{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZfqzG-psHbd"
   },
   "source": [
    "# Neural Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9GBwu1PsSR3"
   },
   "source": [
    "In this notebook we will build a neural machine translation model based on the sequence-to-sequence (seq2seq) models proposed by Sutskever et al., 2014 and Cho et al., 2014. The seq2seq model is widely used in machine translation systems such as Google’s neural machine translation system (GNMT) (Wu et al., 2016).\n",
    "\n",
    "A folder, **nmt_lab_files**  contains 3 files:\n",
    "1. **data.30.vi** - a file. each line of the file contains a Vietnamese sentence to be translated (i.e. the source sentences)\n",
    "2. **data.30.en** - a file. each line of the file contains an English sentence corresponding to the Vietnamese sentence in the same line position. (i.e. the target sentences)\n",
    "3. **nmt_model_keras.py**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyDvxbvTt70n"
   },
   "source": [
    "##**LanguageDict**\n",
    "\n",
    "LanguageDict is a class for creating language dict objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtHvI1pGvMBG"
   },
   "source": [
    "##**The <load_dataset()> Method**\n",
    "\n",
    "This helper method reads from the source and target files to \n",
    "- load max_num_examples sentences, \n",
    "- split the sentences them into train, development and testing, and\n",
    "- return relevant data.\n",
    "The code for this is fully commented. \n",
    "\n",
    "<br>\n",
    "\n",
    "As an example to the kind of ouput returned by this model, let's assume we are translating the sentence 'I like dogs' from English to English (this of course is never the case), such that the tokenized and case normalized source sentence list and target sentence list are as follows:\n",
    "\n",
    "\n",
    "```\n",
    "# In our case this would actually be [['tôi', 'thích', 'thỏ']], i.e the Vietnamese equivalent of the English sentence. \n",
    "# We've used English to English here so we can follow along with the code.\n",
    "source_words = [['i', 'like', 'rabbits']] \n",
    "target_words = [['i', 'like', 'rabbits']]\n",
    "```\n",
    "The word2ids for the source and target language dictionaries would look something like:\n",
    "```\n",
    "source_dict.word2ids = {'<PAD>': 0, '<UNK>': 1, 'i': 2, 'like': 3, 'rabbits':4}\n",
    "\n",
    "# end and start tokens are added for the target words\n",
    "target_dict.word2ids = {'<PAD>': 0, '<UNK>': 1, '<start>': 2, 'i': 3, 'like': 4, 'rabbits':5, '<end>':6}\n",
    "\n",
    "```\n",
    "Let's also assume that we are training and testing on this same dataset of one sentence.\n",
    "The **source words** for train/dev/test will be given as\n",
    "```\n",
    "# a batch_size X max_sent_length array.\n",
    "source_words_train = [[2,3,4]] # corresponding to ['i', 'like', 'rabbits']\n",
    "source_words_dev = [[2,3,4]]  # corresponding to ['i', 'like', 'rabbits']\n",
    "source_words_test = [[2,3,4]] # corresponding to ['i', 'like', 'rabbits']\n",
    "```\n",
    "\n",
    "The **target words** for train data will be given as follows (dev/test don't need target words as the model will provide this):\n",
    "```\n",
    "target_words_train = [[2,3,4,5]] # corresponding to ['<start>', 'i', 'like', 'rabbits']\n",
    "```\n",
    "\n",
    "The **target words labels** for each word will be the word after it. The target word labels for train/dev/test data will be given as follows\n",
    "```\n",
    "target_words_train_labels = [[3,4,5,6]] # corresponding to ['i', 'like', 'rabbits', '<end>']\n",
    "target_words_dev_labels = [[3,4,5,6]] # corresponding to ['i', 'like', 'rabbits', '<end>']\n",
    "target_words_test_labels = [[3,4,5,6]] # corresponding to ['i', 'like', 'rabbits', '<end>']\n",
    "```\n",
    "The dimensions for train target words labels would be expanded to this:\n",
    "`[[3], [4], [5], [6]]`\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cc8KZaJn3uBK"
   },
   "source": [
    "##**The Neural Translation Model (NMT)**\n",
    "\n",
    "For the NMT the network (a system of connected layers/models) used for training differs slightly from the network used for inference. Both use the the seq-to-seq encoder-decoder architecture. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgtz6XAl4E8D"
   },
   "source": [
    "###**The training mode**\n",
    "\n",
    "**Encoder**\n",
    "\n",
    "Given:\n",
    "- `source_words`: a `batch_size(num_sents) x max_sentence_length` array representing the source words. In our mini example, this would be the Vietnamese equivalent of `['i', 'like', 'rabbits']`; `[['tôi', 'thích', 'thỏ']]`\n",
    "\n",
    "The following steps comprise the encoding network:\n",
    "\n",
    "1. transform `source_words` into `source_words_embeddings` using a randomly initialized embedding lookup. source_words_embeddings is thus a `batch_size(num_sents) x max_sentence_length x embedding_dim` array.\n",
    "2. Apply embedding dropout of `embedding_dropout_rate`.\n",
    "3. Use a single `LSTM` with `hidden_size` units to learn a representation for the source words i.e. to encode the input. \n",
    "\n",
    "    (a.) The hidden and cell states for this `LSTM` are initialized to zeros (i.e. we leave the `initial_states = None` default as is).\n",
    "\n",
    "    (b.) We save the `encoder_output` (the sequence not just the last state); and the encoder (hidden and cell) states. \n",
    "\n",
    "This way, the model encodes a representation for the source words. Task 1 guides you to complete the encoder part of the training model.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Decoder (No Attention)**\n",
    "\n",
    "Given:\n",
    "- `target_words`: a `batch_size(i.e.num_sents in batch) x max_sentence_length+1` array representing the target words. This is a time shifted translation of the source words with an added (prepended) `<START>` token `['<start>', 'i', 'like', 'rabbits']`.\n",
    "\n",
    "The decoding is in the following steps:\n",
    "\n",
    "1. transform `target_words` into `target_words_embeddings` using a randomly initialized embedding lookup. target_words_embeddings is thus a `batch_size x max_sentence_length+1 x embedding_dim` array.\n",
    "\n",
    "2.  Apply embedding dropout of `embedding_dropout_rate`.\n",
    "\n",
    "3. Use a single `LSTM` with `hidden_size` units to learn a representation for the target words. Some context is given to this model by using the encoder states to initialize the decoder lstm. This way the encoder state for `'tôi'` for example is used to learn to the representation (and next word prediction, see number 4.) for the `'<start>'` token, and so on.\n",
    "\n",
    "4. For each token representation, use a dense layer to predict a `target_vocab_size` vector which is the probability that any given word in the target vocabulary is the next word following the represented token. The output `decoder_outputs_train` is thus a `batch_size x max_sent_length x target_vocab_size` array.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4tsMpCYJUk1"
   },
   "source": [
    "###**The Inference Mode**\n",
    "\n",
    "**Encoder**\n",
    "\n",
    "The inference time encoding follows the same steps as training time encoding.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Decoder (No attention)**\n",
    "\n",
    "During training time, we passed a `batch_size(num_sents) x max_sentence_length` array representing the target words into the decoder lstm. The decoder_lstm learns how to represent a given target sentence using the context from the encoder lstm (that learns to represent a source sentence).  \n",
    "\n",
    "At test time, several things are different:\n",
    "\n",
    "1. We no longer have access to a complete translation of the source sentence (recall that no target_words array exists for dev and test sets). Rather, we initialize the target_words_array as thus:\n",
    "\n",
    "    Each expected sentence contains only a single token index, the index of the `'<start>'` token. So, the target_word_dev/test is a `batch_size x 1` array. (see the nmt.eval() function for this)\n",
    "\n",
    "2. This `batch_size x 1` array is fed to the trained decoder_lstm and the predicted array is a `batch_size x 1 x target_vocab_size` such that taking the argmax of this array accross the dimension 2 will give the most probable next word. \n",
    "\n",
    "    For example, at time_step `0`, the first time step, where the `step_target_words` given is the `batch_size x 1` array containing the `'<start>'` token, the next word prediction of the decoder is for each sentence (in the batch) the initial word in the sentence. \n",
    "\n",
    "3. At the first time step, the decoder_lstm still uses the encoder_states as it's initial states. At subsequent time steps, it uses it's own states from the previous time steps. This is also what the decoder_lstm does at training time but it is made more explicit here as we loop over time steps using a for loop.\n",
    "(see nmt.eval())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFIKOF5sed68"
   },
   "source": [
    "##**Training Without Attention**\n",
    "\n",
    "If you've completed Tasks 1 and 2, you are ready to train the NMT model without attention.\n",
    "\n",
    "Run the following cells to train the model for 10 epochs. It also shows the model summary of the each model you encapsulated.\n",
    "\n",
    "If you're using a GPU, training will no more than 10 minutes and you will get a BLEU score between 4 and 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8V5YoFP3yQO-",
    "outputId": "628a1543-559e-4649-eb6a-ad084320ed10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "upXa_erqyzKm"
   },
   "outputs": [],
   "source": [
    "# change this to the path to your folder. Remember to start from the home directory\n",
    "PATH = 'My Drive/GTA/nmt_lab_files/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ffbGcgrRy7p6"
   },
   "outputs": [],
   "source": [
    "PATH_TO_FOLDER = \"/content/drive/\" + PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XfSgKakK0QgV"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(PATH_TO_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NmSgv44y0TN9"
   },
   "outputs": [],
   "source": [
    "SOURCE_PATH = PATH_TO_FOLDER + 'data.30.vi'\n",
    "TARGET_PATH = PATH_TO_FOLDER + 'data.30.en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OOTMtc_l0_ut"
   },
   "outputs": [],
   "source": [
    "import nmt as nmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Task 1: Implementing the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    "    Task 1 encoder\n",
    "    \n",
    "    Here we are defining an encoder for encoding the source sequence. First we created embeddings for the source sentences. \n",
    "    We passed this embedding layer to LSTM layer.\n",
    "    In Seq2Seq model we pass the final LSTM cell and hidden states as the initial states to the decoder. \n",
    "    So, in order to obtain that we defined LSTM layer with “return_states” set to True \n",
    "    and when using attention we would need the output for each input to LSTM layer and so we also set “return_sequence” to True.\n",
    "    Then we combine the final LSTM cell output c and hidden state output h and call this variable encoder_outputs which \n",
    "    we pass as hidden state to the decoder. \n",
    "    \n",
    "    After this a model is created which will take two inputs, source_words and target_words and output decoded outputs sequence\n",
    "    \n",
    "    Start\n",
    "    \"\"\"\n",
    "    # The train encoder\n",
    "    # (a.) Create two randomly initialized embedding lookups, one for the source, another for the target. \n",
    "    print('Task 1(a): Creating the embedding lookups...')\n",
    "    embeddings_source = Embedding(self.vocab_source_size, self.embedding_size, name='Embedding_source',\n",
    "                        \tembeddings_initializer='glorot_uniform',mask_zero=True)(source_words)\n",
    "                         \t\n",
    "        \n",
    "    embeddings_target = Embedding(self.vocab_target_size, self.embedding_size, name='Embedding_target',\n",
    "                        \tembeddings_initializer='glorot_uniform',mask_zero=True)(target_words)\n",
    "                         \t\n",
    "    \n",
    "    # (b.) Look up the embeddings for source words and for target words. Apply dropout to each encoded input\n",
    "    print('\\nTask 1(b): Looking up source and target words...')\n",
    "    source_word_embeddings = Dropout(self.embedding_dropout_rate)(embeddings_source)\n",
    "\n",
    "    target_words_embeddings = Dropout(self.embedding_dropout_rate)(embeddings_target)\n",
    "\n",
    "    # (c.) An encoder LSTM() with return sequences set to True\n",
    "    print('\\nTask 1(c): Creating an encoder')\n",
    "    # By setting return_sequences to True the layer will return hidden state(h) output for each input\n",
    "    # By setting return_state to True the layer will return the final cell state(c) output and the final hidden state(h) output\n",
    "    # which decoder will use to initialise their cell states\n",
    "  \n",
    "    encoder_outputs, encoder_state_h, encoder_state_c = LSTM(self.hidden_size, return_sequences=True,\n",
    "                                                             return_state=True)(source_word_embeddings)\n",
    "    \"\"\"\n",
    "    End Task 1\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here we are defining an encoder for encoding the source sequence. First we created embeddings for the source sentences. We passed this embedding layer to LSTM layer.<br><br>\n",
    "\n",
    "* In Seq2Seq model we pass the final LSTM cell and hidden states as the initial states to the decoder. So, in order to obtain that we defined LSTM layer with “return_states” set to True and when using attention we would need the output for each input to LSTM layer and so we also set “return_sequence” to True. Then we combine the final LSTM cell output c and hidden state output h and call this variable encoder_outputs which we pass as hidden state to the decoder.<br><br>\n",
    "\n",
    "* After this a model is created which will take two inputs, source_words and target_words and output decoded outputs sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implementing the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Task 2 decoder for inference\n",
    "    \n",
    "    Start\n",
    "    \"\"\"\n",
    "    # Task 1 (a.) Get the decoded outputs\n",
    "    print('\\n Putting together the decoder states')\n",
    "    # get the inititial states for the decoder, decoder_states\n",
    "    # decoder states are the hidden and cell states from the training stage\n",
    "    decoder_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "    # use decoder states as input to the decoder lstm to get the decoder outputs, h, and c for test time inference\n",
    "    decoder_outputs_test,decoder_state_output_h, decoder_state_output_c = decoder_lstm(target_words_embeddings,\n",
    "                                                                                       initial_state=decoder_states )\n",
    "\n",
    "\n",
    "    # Task 1 (b.) Add attention if attention\n",
    "    if self.use_attention:\n",
    "      decoder_attention = AttentionLayer()\n",
    "      decoder_outputs_test = decoder_attention([encoder_outputs,decoder_outputs_test])\n",
    "\n",
    "\n",
    "    # Task 1 (c.) pass the decoder_outputs_test (with or without attention) to the decoder dense layer\n",
    "    decoder_outputs_test = decoder_dense(decoder_outputs_test)\n",
    "    \n",
    "    \"\"\"\n",
    "    End Task 2 \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here we are defining the decoder inference model.<br><br>\n",
    "\n",
    "* For the decoder inference model, we use the states that are passed to the decoder_model as the initial states to the decoder_lstm, a layer that was defined in the training stage.<br><br>\n",
    "\n",
    "* The decoder_model will take as input target_words,decoder_state_input_h,decoder_state_input_c,encoder_outputs_input and return decoder_outputs_test,decoder_state_output_h,decoder_state_output_c. In eval method while in the loop the decoder_model  is used to predict step_decoder_outputs, state_h, state_c. The maximum of step_decoder_outputs is taken and appended to the list predictions. state_h and state_c(newly predicted) are again passed to the model as input to predict the next word.<br><br>\n",
    "\n",
    "* Without Attention we obtained the BLEU score of 5.64.\n",
    "\n",
    "* The sample output can be found in the below cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xg7wcRcaHYUi",
    "outputId": "364e6420-6132-4c17-e17d-ad4ae9d02639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dictionaries\n",
      "read 24000/3000/3000 train/dev/test batches\n",
      "number of tokens in source: 2034, number of tokens in target:2506\n",
      "Task 1(a): Creating the embedding lookups...\n",
      "\n",
      "Task 1(b): Looking up source and target words...\n",
      "\n",
      "Task 1(c): Creating an encoder\n",
      "encoder_outputs: (None, None, 200)\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\t\t\t\t\t\t Train Model Summary.\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " Embedding_source (Embedding)   (None, None, 100)    203400      ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " Embedding_target (Embedding)   (None, None, 100)    250600      ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, None, 100)    0           ['Embedding_source[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, None, 100)    0           ['Embedding_target[0][0]']       \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  [(None, None, 200),  240800      ['dropout_4[0][0]']              \n",
      "                                 (None, 200),                                                     \n",
      "                                 (None, 200)]                                                     \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  [(None, None, 200),  240800      ['dropout_5[0][0]',              \n",
      "                                 (None, 200),                     'lstm_4[0][1]',                 \n",
      "                                 (None, 200)]                     'lstm_4[0][2]']                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, None, 2506)   503706      ['lstm_5[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,439,306\n",
      "Trainable params: 1,439,306\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\t\t\t\t\t\t Inference Time Encoder Model Summary.\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, None)]            0         \n",
      "                                                                 \n",
      " Embedding_source (Embedding  (None, None, 100)        203400    \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               [(None, None, 200),       240800    \n",
      "                              (None, 200),                       \n",
      "                              (None, 200)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 444,200\n",
      "Trainable params: 444,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Putting together the decoder states\n",
      "\t\t\t\t\t\t Decoder Inference Model summary\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " Embedding_target (Embedding)   (None, None, 100)    250600      ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, None, 100)    0           ['Embedding_target[0][0]']       \n",
      "                                                                                                  \n",
      " input_13 (InputLayer)          [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  [(None, None, 200),  240800      ['dropout_5[0][0]',              \n",
      "                                 (None, 200),                     'input_13[0][0]',               \n",
      "                                 (None, 200)]                     'input_14[0][0]']               \n",
      "                                                                                                  \n",
      " input_15 (InputLayer)          [(None, None, 200)]  0           []                               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, None, 2506)   503706      ['lstm_5[1][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 995,106\n",
      "Trainable params: 995,106\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Starting training epoch 1/10\n",
      "240/240 [==============================] - 19s 65ms/step - loss: 2.1165 - accuracy: 0.2456\n",
      "Time used for epoch 1: 0 m 19 s\n",
      "Evaluating on dev set after epoch 1/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "and i &apos;m going to be <unk> , and i &apos;m going to <unk> <unk> , and i &apos;m going to be <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "and i &apos;m going to be <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "and i &apos;m going to be <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and i &apos;m going to be <unk> , and i &apos;m going to be <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "it &apos;s <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 1.47\n",
      "Time used for evaluate on dev set: 0 m 8 s\n",
      "Starting training epoch 2/10\n",
      "240/240 [==============================] - 16s 65ms/step - loss: 1.8141 - accuracy: 0.3098\n",
      "Time used for epoch 2: 0 m 15 s\n",
      "Evaluating on dev set after epoch 2/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "and the <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but it &apos;s a <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "<unk> <unk> : <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and it &apos;s a <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this is a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 2.50\n",
      "Time used for evaluate on dev set: 0 m 6 s\n",
      "Starting training epoch 3/10\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.6924 - accuracy: 0.3424\n",
      "Time used for epoch 3: 0 m 15 s\n",
      "Evaluating on dev set after epoch 3/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there are a <unk> <unk> , and i &apos;m going to be <unk> , and i &apos;m going to be <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but here &apos;s a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "<unk> <unk> : <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and i &apos;m going to be a <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this is a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 3.79\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 4/10\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 1.6151 - accuracy: 0.3606\n",
      "Time used for epoch 4: 0 m 20 s\n",
      "Evaluating on dev set after epoch 4/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there &apos;s a <unk> <unk> , and i was <unk> to <unk> <unk> <unk> , and i was <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but this is a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "the <unk> <unk> is <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and i &apos;m not going to be able to do it .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this is a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 3.77\n",
      "Time used for evaluate on dev set: 0 m 6 s\n",
      "Starting training epoch 5/10\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.5581 - accuracy: 0.3715\n",
      "Time used for epoch 5: 0 m 15 s\n",
      "Evaluating on dev set after epoch 5/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there are a <unk> <unk> , and it &apos;s a <unk> <unk> , and it &apos;s a <unk> <unk> in the <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but it &apos;s a <unk> of <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "the <unk> <unk> <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and i &apos;m going to be able to be able to be a <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this is the <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 4.44\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 6/10\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.5162 - accuracy: 0.3795\n",
      "Time used for epoch 6: 0 m 15 s\n",
      "Evaluating on dev set after epoch 6/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there &apos;s a <unk> <unk> , and i <unk> the <unk> of the <unk> of <unk> and <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but this is a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "the <unk> <unk> is a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and i &apos;m not going to be <unk> by the <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this is a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 4.42\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 7/10\n",
      "240/240 [==============================] - 16s 65ms/step - loss: 1.4818 - accuracy: 0.3848\n",
      "Time used for epoch 7: 0 m 15 s\n",
      "Evaluating on dev set after epoch 7/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there are <unk> , and the <unk> , the <unk> , the <unk> , the <unk> , the <unk> of the <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but this is a <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "the <unk> <unk> is <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and i &apos;m not going to talk about the <unk> of the <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this is a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 4.86\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 8/10\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 1.4544 - accuracy: 0.3893\n",
      "Time used for epoch 8: 0 m 16 s\n",
      "Evaluating on dev set after epoch 8/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there are a <unk> , and the <unk> <unk> , the <unk> <unk> , the <unk> of the <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but this is the <unk> of the <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "the <unk> is <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and i &apos;m going to be <unk> , and it &apos;s a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this is the <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 4.91\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 9/10\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 1.4314 - accuracy: 0.3930\n",
      "Time used for epoch 9: 0 m 16 s\n",
      "Evaluating on dev set after epoch 9/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there are <unk> , and it &apos;s a <unk> , and it &apos;s a <unk> <unk> , and it &apos;s a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but this is what it is .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "it &apos;s called <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and you can see the <unk> of the <unk> of the <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this is a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 5.35\n",
      "Time used for evaluate on dev set: 0 m 6 s\n",
      "Starting training epoch 10/10\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 1.4104 - accuracy: 0.3969\n",
      "Time used for epoch 10: 0 m 16 s\n",
      "Evaluating on dev set after epoch 10/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there &apos;s a <unk> <unk> , and i <unk> the <unk> <unk> <unk> <unk> and <unk> and <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but this is the <unk> of the <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "it &apos;s a <unk> <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and you can see the <unk> <unk> of the <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this is a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 5.45\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Training finished!\n",
      "Time used for training: 3 m 59 s\n",
      "Evaluating on test set:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "the <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "the second quote is from the head of the u.k. financial services <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "the <unk> is <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it gets worse .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "what &apos;s the last example is going to be <unk> ?\n",
      "\n",
      "This is the target sentence: \n",
      "what &apos;s happening here ? how can this be possible ?\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "it &apos;s not a <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "unfortunately , the answer is yes .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "but it &apos;s a <unk> that &apos;s <unk> , and it &apos;s a <unk> <unk> of <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but there &apos;s an <unk> solution which is coming from what is known as the science of <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 5.64\n",
      "Time used for evaluate on test set: 0 m 6 s\n"
     ]
    }
   ],
   "source": [
    "nmt.main(SOURCE_PATH, TARGET_PATH, use_attention=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "IsO7wW6U1w2m",
    "outputId": "c8dcfa85-47b9-4e54-ec5e-aeab46756e0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dictionaries\n",
      "read 24000/3000/3000 train/dev/test batches\n",
      "source vocab: 2034, target vocab:2506\n",
      "\t\t\t\t\t\tSummary of the train model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 100)    203400      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    250600      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 100)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 100)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer/model (LSTM)      [(None, None, 200),  240800      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer/model (LSTM)      [(None, None, 200),  240800      dropout_1[0][0]                  \n",
      "                                                                 encoder_layer/model[0][1]        \n",
      "                                                                 encoder_layer/model[0][2]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 2506)   503706      decoder_layer/model[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,439,306\n",
      "Trainable params: 1,439,306\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\t\t\t\t\t\tSummary of the encoder model\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 100)         203400    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "encoder_layer/model (LSTM)   [(None, None, 200), (None 240800    \n",
      "=================================================================\n",
      "Total params: 444,200\n",
      "Trainable params: 444,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\t\t\t\t\t\tSummary of the decoder model\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    250600      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 100)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer/model (LSTM)      [(None, None, 200),  240800      dropout_1[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, None, 200)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 2506)   503706      decoder_layer/model[1][0]        \n",
      "==================================================================================================\n",
      "Total params: 995,106\n",
      "Trainable params: 995,106\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Starting training epoch 1/10\n",
      "240/240 [==============================] - 204s 837ms/step - loss: 2.3722 - accuracy: 0.1962\n",
      "Time used for epoch 1: 3 m 24 s\n",
      "Evaluating on dev set after epoch 1/10:\n",
      "Model BLEU score: 2.01\n",
      "Time used for evaluate on dev set: 0 m 11 s\n",
      "Starting training epoch 2/10\n",
      "240/240 [==============================] - 202s 840ms/step - loss: 1.8103 - accuracy: 0.3097\n",
      "Time used for epoch 2: 3 m 21 s\n",
      "Evaluating on dev set after epoch 2/10:\n",
      "Model BLEU score: 3.05\n",
      "Time used for evaluate on dev set: 0 m 11 s\n",
      "Starting training epoch 3/10\n",
      "240/240 [==============================] - 202s 840ms/step - loss: 1.6898 - accuracy: 0.3420\n",
      "Time used for epoch 3: 3 m 21 s\n",
      "Evaluating on dev set after epoch 3/10:\n",
      "Model BLEU score: 3.96\n",
      "Time used for evaluate on dev set: 0 m 11 s\n",
      "Starting training epoch 4/10\n",
      "240/240 [==============================] - 203s 846ms/step - loss: 1.6114 - accuracy: 0.3598\n",
      "Time used for epoch 4: 3 m 23 s\n",
      "Evaluating on dev set after epoch 4/10:\n",
      "Model BLEU score: 4.17\n",
      "Time used for evaluate on dev set: 0 m 11 s\n",
      "Starting training epoch 5/10\n",
      "240/240 [==============================] - 204s 850ms/step - loss: 1.5567 - accuracy: 0.3703\n",
      "Time used for epoch 5: 3 m 23 s\n",
      "Evaluating on dev set after epoch 5/10:\n",
      "Model BLEU score: 4.95\n",
      "Time used for evaluate on dev set: 0 m 11 s\n",
      "Starting training epoch 6/10\n",
      "240/240 [==============================] - 202s 843ms/step - loss: 1.5153 - accuracy: 0.3784\n",
      "Time used for epoch 6: 3 m 22 s\n",
      "Evaluating on dev set after epoch 6/10:\n",
      "Model BLEU score: 5.26\n",
      "Time used for evaluate on dev set: 0 m 11 s\n",
      "Starting training epoch 7/10\n",
      "240/240 [==============================] - 199s 830ms/step - loss: 1.4798 - accuracy: 0.3841\n",
      "Time used for epoch 7: 3 m 19 s\n",
      "Evaluating on dev set after epoch 7/10:\n",
      "Model BLEU score: 5.39\n",
      "Time used for evaluate on dev set: 0 m 11 s\n",
      "Starting training epoch 8/10\n",
      "240/240 [==============================] - 199s 827ms/step - loss: 1.4514 - accuracy: 0.3889\n",
      "Time used for epoch 8: 3 m 18 s\n",
      "Evaluating on dev set after epoch 8/10:\n",
      "Model BLEU score: 5.69\n",
      "Time used for evaluate on dev set: 0 m 10 s\n",
      "Starting training epoch 9/10\n",
      "240/240 [==============================] - 199s 828ms/step - loss: 1.4278 - accuracy: 0.3927\n",
      "Time used for epoch 9: 3 m 18 s\n",
      "Evaluating on dev set after epoch 9/10:\n",
      "Model BLEU score: 5.69\n",
      "Time used for evaluate on dev set: 0 m 11 s\n",
      "Starting training epoch 10/10\n",
      "240/240 [==============================] - 200s 832ms/step - loss: 1.4069 - accuracy: 0.3962\n",
      "Time used for epoch 10: 3 m 19 s\n",
      "Evaluating on dev set after epoch 10/10:\n",
      "Model BLEU score: 6.16\n",
      "Time used for evaluate on dev set: 0 m 11 s\n",
      "Training finished!\n",
      "Time used for training: 35 m 25 s\n",
      "Evaluating on test set:\n",
      "Model BLEU score: 6.19\n",
      "Time used for evaluate on test set: 0 m 10 s\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlMDC3DJi12c"
   },
   "source": [
    "##**Decoding with Attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cQKwvFqurVY"
   },
   "source": [
    "The inputs to the attention layer are encoder and decoder outputs. The attention mechanism:\n",
    "1. Computes a score (a luong score) for each source word\n",
    "2. Weights the words by their luong scores.\n",
    "3. Concatenates the wieghted encoder representation with the decoder_ouput.\n",
    "This new decoder output will now be the input to the decoder_dense layer. \n",
    "\n",
    "Task 3 description in the doc file outlines the steps for this in detail. Once you have completed this Task, you are now ready to train with attention. Training time will be no more than 10 minutes using a GPU and you should get a bleu score of about 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adding Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Task 3 attention\n",
    "    \n",
    "    Start\n",
    "    \"\"\"\n",
    "    # transponsing the decoder_outputs\n",
    "    # in the keras backend the indexing of the input shape starts at 0\n",
    "    # our input shape is [batch_size,max_target_sent_len, hidden_size] and we want to transpose to \n",
    "    # [batch_size,hidden_size,max_target_sent_len], in terms of indexing we want to [0,1,2] to [0,2,1] \n",
    "    # and so the pattern is (0,2,1)\n",
    "    decoder_outputs_transposed = K.permute_dimensions(decoder_outputs,pattern=(0,2,1))\n",
    "    \n",
    "    \n",
    "    # the dimension of encoder_outputs is [batch_size, hidden_size, max_source_sent_len]\n",
    "    # the dimension of decoder_outputs_transposed is [batch_size, max_target_sent_len, hidden_size]\n",
    "    # We want the dimension of luong_score to be [batch_size, max_source_sent_len, max_target_sent_len] which can be obtained when\n",
    "    # perform batch_dot on axes = [2,1] but since that is by default we havent defined it below\n",
    "    luong_score = K.batch_dot(encoder_outputs,decoder_outputs_transposed)\n",
    "    \n",
    "    # since the indexing starts from 0 we have axis =1\n",
    "    # Take softmax to turn the scores into probabibility distribution\n",
    "    luong_score = softmax(luong_score, axis = 1)\n",
    "    \n",
    "    # expanding the dimensions\n",
    "    # here the indexing starts at 1\n",
    "    # the shape of encoder_ouputs in terms of indexing is [1,2,3] and we want to transform it \n",
    "    # to shape of [1,2,1,3](in terms of indexing) and so we select axis = 2\n",
    "    encoder_outputs_expanded = K.expand_dims(encoder_outputs,axis = 2)\n",
    "    \n",
    "    # the shape of luong_score in terms of indexing is [1,2,3] and we want to transform it \n",
    "    # to shape of [1,2,3,1](in terms of indexing) and so we select axis = 3\n",
    "    luong_score = K.expand_dims(luong_score,axis = 3)\n",
    "    \n",
    "    # weighted sum of the encoder hidden states\n",
    "    multiplication  = luong_score * encoder_outputs_expanded\n",
    "    \n",
    "    # sum along \"max_source_sent_len\" dimension\n",
    "    # since indexing begins from 0, the axis = 1\n",
    "    encoder_vector = K.sum(multiplication , axis = 1)\n",
    "    \n",
    "    \"\"\"\n",
    "    End Task 3\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First we want to calculate the attention scores. To calculate  the attention scores we need to find the dot product between decoder_outputs and encoder_outputs but since both have the same dimensions we transposed the decoder_outputs to now have dimension of [batch_size,hidden_size,max_target_sent_len]. We now perform the dot product and store it in the variable luong_score.<br><br>\n",
    "\n",
    "* We then take the softmax to turn the scores into a probability distribution by taking the softmax of  luong_score along axis 1.<br><br>\n",
    "\n",
    "* We then  performed element-wise multiplication of encoder_outputs and luong_score(after applying softmax along axis 1). Since the dimensions for encoder_outputs and luong_score were not same we expanded their dimensions and this way we obtained Attention output called encoder_vector in our model.<br><br>\n",
    "\n",
    "* Finally, we concatenate encoder_vector with decoder_outputs and this is now our new decoder_outputs which will be now passed to decoder_dense and follow the steps as the model did before adding Attention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CM-Lli4UBjLr",
    "outputId": "8ca864bb-601d-4b59-d365-c79b35a4eaf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dictionaries\n",
      "read 24000/3000/3000 train/dev/test batches\n",
      "number of tokens in source: 2034, number of tokens in target:2506\n",
      "Task 1(a): Creating the embedding lookups...\n",
      "\n",
      "Task 1(b): Looking up source and target words...\n",
      "\n",
      "Task 1(c): Creating an encoder\n",
      "encoder_outputs: (None, None, 200)\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\t\t\t\t\t\t Train Model Summary.\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " Embedding_source (Embedding)   (None, None, 100)    203400      ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, None, 100)    0           ['Embedding_source[0][0]']       \n",
      "                                                                                                  \n",
      " Embedding_target (Embedding)   (None, None, 100)    250600      ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, None, 200),  240800      ['dropout_2[0][0]']              \n",
      "                                 (None, 200),                                                     \n",
      "                                 (None, 200)]                                                     \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, None, 100)    0           ['Embedding_target[0][0]']       \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 200),  240800      ['dropout_3[0][0]',              \n",
      "                                 (None, 200),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 200)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " attention_layer_2 (AttentionLa  (None, None, 400)   0           ['lstm_2[0][0]',                 \n",
      " yer)                                                             'lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, None, 2506)   1004906     ['attention_layer_2[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,940,506\n",
      "Trainable params: 1,940,506\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\t\t\t\t\t\t Inference Time Encoder Model Summary.\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " Embedding_source (Embedding  (None, None, 100)        203400    \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               [(None, None, 200),       240800    \n",
      "                              (None, 200),                       \n",
      "                              (None, 200)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 444,200\n",
      "Trainable params: 444,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Putting together the decoder states\n",
      "\t\t\t\t\t\t Decoder Inference Model summary\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " Embedding_target (Embedding)   (None, None, 100)    250600      ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, None, 100)    0           ['Embedding_target[0][0]']       \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, None, 200)]  0           []                               \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 200),  240800      ['dropout_3[0][0]',              \n",
      "                                 (None, 200),                     'input_8[0][0]',                \n",
      "                                 (None, 200)]                     'input_9[0][0]']                \n",
      "                                                                                                  \n",
      " attention_layer_3 (AttentionLa  (None, None, 400)   0           ['input_10[0][0]',               \n",
      " yer)                                                             'lstm_3[1][0]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, None, 2506)   1004906     ['attention_layer_3[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,496,306\n",
      "Trainable params: 1,496,306\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Starting training epoch 1/10\n",
      "240/240 [==============================] - 20s 68ms/step - loss: 2.0619 - accuracy: 0.2679\n",
      "Time used for epoch 1: 0 m 20 s\n",
      "Evaluating on dev set after epoch 1/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there &apos;s a <unk> , it &apos;s a <unk> , but it &apos;s a <unk> , it &apos;s a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but it &apos;s not a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "the <unk> of the <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and you can &apos;t see it , and it &apos;s a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this is a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 4.99\n",
      "Time used for evaluate on dev set: 0 m 8 s\n",
      "Starting training epoch 2/10\n",
      "240/240 [==============================] - 16s 68ms/step - loss: 1.5497 - accuracy: 0.4083\n",
      "Time used for epoch 2: 0 m 16 s\n",
      "Evaluating on dev set after epoch 2/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there &apos;s about <unk> , to the <unk> , to the <unk> , it &apos;s <unk> when it &apos;s the <unk> , it &apos;s <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but here &apos;s a very important .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "<unk> <unk> is <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and you can see this is a <unk> <unk> <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this is the <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 11.55\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 3/10\n",
      "240/240 [==============================] - 17s 69ms/step - loss: 1.2875 - accuracy: 0.4680\n",
      "Time used for epoch 3: 0 m 16 s\n",
      "Evaluating on dev set after epoch 3/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there &apos;s four <unk> , and it &apos;s <unk> when it &apos;s <unk> , it &apos;s <unk> , it &apos;s <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but this is really <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "it &apos;s <unk> by the axis .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and so you can see this is a <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this is the way .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 13.76\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 4/10\n",
      "240/240 [==============================] - 16s 69ms/step - loss: 1.1418 - accuracy: 0.4996\n",
      "Time used for epoch 4: 0 m 16 s\n",
      "Evaluating on dev set after epoch 4/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there are four <unk> <unk> when it came over when it died when it died to the images , it took a <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but this is actually just the beginning .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "<unk> <unk> around the <unk> structure .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and you can see here is the <unk> <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "it can be <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 14.62\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 5/10\n",
      "240/240 [==============================] - 16s 69ms/step - loss: 1.0514 - accuracy: 0.5221\n",
      "Time used for epoch 5: 0 m 16 s\n",
      "Evaluating on dev set after epoch 5/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there &apos;s four <unk> <unk> , and the times , it &apos;s <unk> when it died after that , it &apos;s <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but here really is really <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "<unk> <unk> <unk> <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and you can see this is the <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this is <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 15.32\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 6/10\n",
      "240/240 [==============================] - 17s 69ms/step - loss: 0.9909 - accuracy: 0.5371\n",
      "Time used for epoch 6: 0 m 16 s\n",
      "Evaluating on dev set after epoch 6/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there &apos;s four <unk> of control , and then you have to <unk> the images , it was <unk> by the <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but this is not just the beginning .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "it &apos;s been by <unk> <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and you can see here the <unk> have <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this body can be <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 15.49\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 7/10\n",
      "240/240 [==============================] - 17s 69ms/step - loss: 0.9443 - accuracy: 0.5485\n",
      "Time used for epoch 7: 0 m 16 s\n",
      "Evaluating on dev set after epoch 7/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "the four <unk> of control , and then you have a <unk> when it died along with the mirror , it looks like <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but this is really <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "it &apos;s been by <unk> <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and you can see this as a <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this is the <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 15.64\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 8/10\n",
      "240/240 [==============================] - 16s 69ms/step - loss: 0.9063 - accuracy: 0.5603\n",
      "Time used for epoch 8: 0 m 16 s\n",
      "Evaluating on dev set after epoch 8/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there &apos;s four different control , and for this time , it &apos;s <unk> when it died along with the images , it took a <unk> position .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but this is actually the beginning of the <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "it &apos;s <unk> by <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and you can see here as a <unk> of <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this body can be <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 15.52\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 9/10\n",
      "240/240 [==============================] - 17s 70ms/step - loss: 0.8789 - accuracy: 0.5676\n",
      "Time used for epoch 9: 0 m 16 s\n",
      "Evaluating on dev set after epoch 9/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there &apos;s four four basic control , and then you take a <unk> back when it comes to the photo , it feels like noise .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but this really is really just really <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "<unk> <unk> <unk> around two meters .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and you can see this as a <unk> <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this can <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 15.69\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Starting training epoch 10/10\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 0.8555 - accuracy: 0.5744\n",
      "Time used for epoch 10: 0 m 17 s\n",
      "Evaluating on dev set after epoch 10/10:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "there &apos;s four <unk> control , and the time that when it comes to the <unk> , it &apos;s <unk> to the images , it feels like <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "but this is not just the warm early .\n",
      "\n",
      "This is the target sentence: \n",
      "but this is really just the beginning .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "<unk> <unk> <unk> around two million .\n",
      "\n",
      "This is the target sentence: \n",
      "it <unk> this by <unk> <unk> about two <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "and you can see here the <unk> have been <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "so as you can see here , this is a , <unk> <unk> <unk> board .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "this <unk> can <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "these blocks <unk> <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 15.53\n",
      "Time used for evaluate on dev set: 0 m 7 s\n",
      "Training finished!\n",
      "Time used for training: 4 m 4 s\n",
      "Evaluating on test set:\n",
      "### SAMPLE  1 ###\n",
      "This is the translated sentence: \n",
      "the second signal was coming from the <unk> <unk> <unk> <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "the second quote is from the head of the u.k. financial services <unk> .\n",
      "------------------------------------------\n",
      "### SAMPLE  2 ###\n",
      "This is the translated sentence: \n",
      "so the worse is more than that .\n",
      "\n",
      "This is the target sentence: \n",
      "it gets worse .\n",
      "------------------------------------------\n",
      "### SAMPLE  3 ###\n",
      "This is the translated sentence: \n",
      "what &apos;s happening here ? how could it be ?\n",
      "\n",
      "This is the target sentence: \n",
      "what &apos;s happening here ? how can this be possible ?\n",
      "------------------------------------------\n",
      "### SAMPLE  4 ###\n",
      "This is the translated sentence: \n",
      "unfortunately , the answer is right now .\n",
      "\n",
      "This is the target sentence: \n",
      "unfortunately , the answer is yes .\n",
      "------------------------------------------\n",
      "### SAMPLE  5 ###\n",
      "This is the translated sentence: \n",
      "but , there &apos;s a very interesting solution to the <unk> from the <unk> that &apos;s <unk> to the <unk> .\n",
      "\n",
      "This is the target sentence: \n",
      "but there &apos;s an <unk> solution which is coming from what is known as the science of <unk> .\n",
      "------------------------------------------\n",
      "Model BLEU score: 16.10\n",
      "Time used for evaluate on test set: 0 m 7 s\n"
     ]
    }
   ],
   "source": [
    "nmt.main(SOURCE_PATH, TARGET_PATH, use_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23t6wfpLkb2F",
    "outputId": "db7e09dc-f5da-4083-8ac8-89875e1b9fc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dictionaries\n",
      "read 24000/3000/3000 train/dev/test batches\n",
      "source vocab: 2034, target vocab:2506\n",
      "WARNING:tensorflow:Layer encoder_layer/model will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer decoder_layer/model will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\t\t\t\t\t\tSummary of the train model\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 100)    203400      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 100)    0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 100)    250600      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer/model (LSTM)      [(None, None, 200),  240800      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 100)    0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer/model (LSTM)      [(None, None, 200),  240800      dropout_3[0][0]                  \n",
      "                                                                 encoder_layer/model[0][1]        \n",
      "                                                                 encoder_layer/model[0][2]        \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer/model (Attentio (None, None, 400)    0           encoder_layer/model[0][0]        \n",
      "                                                                 decoder_layer/model[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 2506)   1004906     attention_layer/model[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 1,940,506\n",
      "Trainable params: 1,940,506\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\t\t\t\t\t\tSummary of the encoder model\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, None, 100)         203400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "encoder_layer/model (LSTM)   [(None, None, 200), (None 240800    \n",
      "=================================================================\n",
      "Total params: 444,200\n",
      "Trainable params: 444,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\t\t\t\t\t\tSummary of the decoder model\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 100)    250600      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 100)    0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, None, 200)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer/model (LSTM)      [(None, None, 200),  240800      dropout_3[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer/model (Attentio (None, None, 400)    0           input_10[0][0]                   \n",
      "                                                                 decoder_layer/model[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 2506)   1004906     attention_layer/model[1][0]      \n",
      "==================================================================================================\n",
      "Total params: 1,496,306\n",
      "Trainable params: 1,496,306\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Starting training epoch 1/10\n",
      "240/240 [==============================] - 27s 103ms/step - loss: 2.3337 - accuracy: 0.2114\n",
      "Time used for epoch 1: 0 m 27 s\n",
      "Evaluating on dev set after epoch 1/10:\n",
      "Model BLEU score: 4.79\n",
      "Time used for evaluate on dev set: 0 m 5 s\n",
      "Starting training epoch 2/10\n",
      "240/240 [==============================] - 24s 101ms/step - loss: 1.5835 - accuracy: 0.3952\n",
      "Time used for epoch 2: 0 m 24 s\n",
      "Evaluating on dev set after epoch 2/10:\n",
      "Model BLEU score: 10.02\n",
      "Time used for evaluate on dev set: 0 m 5 s\n",
      "Starting training epoch 3/10\n",
      "240/240 [==============================] - 24s 100ms/step - loss: 1.3438 - accuracy: 0.4478\n",
      "Time used for epoch 3: 0 m 23 s\n",
      "Evaluating on dev set after epoch 3/10:\n",
      "Model BLEU score: 12.79\n",
      "Time used for evaluate on dev set: 0 m 5 s\n",
      "Starting training epoch 4/10\n",
      "240/240 [==============================] - 25s 102ms/step - loss: 1.1991 - accuracy: 0.4791\n",
      "Time used for epoch 4: 0 m 24 s\n",
      "Evaluating on dev set after epoch 4/10:\n",
      "Model BLEU score: 14.24\n",
      "Time used for evaluate on dev set: 0 m 5 s\n",
      "Starting training epoch 5/10\n",
      "240/240 [==============================] - 24s 99ms/step - loss: 1.1095 - accuracy: 0.4998\n",
      "Time used for epoch 5: 0 m 23 s\n",
      "Evaluating on dev set after epoch 5/10:\n",
      "Model BLEU score: 14.33\n",
      "Time used for evaluate on dev set: 0 m 5 s\n",
      "Starting training epoch 6/10\n",
      "240/240 [==============================] - 23s 97ms/step - loss: 1.0475 - accuracy: 0.5149\n",
      "Time used for epoch 6: 0 m 23 s\n",
      "Evaluating on dev set after epoch 6/10:\n",
      "Model BLEU score: 14.48\n",
      "Time used for evaluate on dev set: 0 m 5 s\n",
      "Starting training epoch 7/10\n",
      "240/240 [==============================] - 25s 104ms/step - loss: 1.0005 - accuracy: 0.5273\n",
      "Time used for epoch 7: 0 m 25 s\n",
      "Evaluating on dev set after epoch 7/10:\n",
      "Model BLEU score: 14.53\n",
      "Time used for evaluate on dev set: 0 m 5 s\n",
      "Starting training epoch 8/10\n",
      "240/240 [==============================] - 24s 102ms/step - loss: 0.9645 - accuracy: 0.5366\n",
      "Time used for epoch 8: 0 m 24 s\n",
      "Evaluating on dev set after epoch 8/10:\n",
      "Model BLEU score: 15.11\n",
      "Time used for evaluate on dev set: 0 m 5 s\n",
      "Starting training epoch 9/10\n",
      "240/240 [==============================] - 25s 102ms/step - loss: 0.9364 - accuracy: 0.5442\n",
      "Time used for epoch 9: 0 m 24 s\n",
      "Evaluating on dev set after epoch 9/10:\n",
      "Model BLEU score: 15.02\n",
      "Time used for evaluate on dev set: 0 m 5 s\n",
      "Starting training epoch 10/10\n",
      "240/240 [==============================] - 24s 100ms/step - loss: 0.9110 - accuracy: 0.5515\n",
      "Time used for epoch 10: 0 m 23 s\n",
      "Evaluating on dev set after epoch 10/10:\n",
      "Model BLEU score: 14.91\n",
      "Time used for evaluate on dev set: 0 m 5 s\n",
      "Training finished!\n",
      "Time used for training: 5 m 0 s\n",
      "Evaluating on test set:\n",
      "Model BLEU score: 15.43\n",
      "Time used for evaluate on test set: 0 m 5 s\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab5_6_NeuralMachineTranslation_studentEdition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
